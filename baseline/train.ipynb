{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchaudio import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data import Sep28K\n",
    "from models import LSTMModel\n",
    "\n",
    "def set_seed(seed):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "TASK_TYPE = 'mtl'\n",
    "_writer = SummaryWriter(log_dir = './logs',comment=TASK_TYPE)\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CCCLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CCCLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        y_true_mean = torch.mean(y_true, dim=1, keepdim=True)\n",
    "        y_pred_mean = torch.mean(y_pred, dim=1, keepdim=True)\n",
    "        \n",
    "        y_true_var = torch.var(y_true, dim=1, unbiased=False)\n",
    "        y_pred_var = torch.var(y_pred, dim=1, unbiased=False)\n",
    "        \n",
    "        covariance = torch.mean((y_true - y_true_mean) * (y_pred - y_pred_mean), dim=1)\n",
    "        \n",
    "        ccc = (2 * covariance) / (y_true_var + y_pred_var + (y_true_mean - y_pred_mean).squeeze() ** 2)\n",
    "        \n",
    "        ccc_loss = 1 - ccc.mean()\n",
    "\n",
    "        return ccc_loss\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self, writer: SummaryWriter = None, name=None):\n",
    "        self.reset()\n",
    "        self._writer = writer\n",
    "        self._name = name\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val \n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def write(self, epoch):\n",
    "        self._writer.add_scalar(self._name + '/val', self.avg, epoch)\n",
    "\n",
    "# configurations\n",
    "from yacs.config import CfgNode as CN\n",
    "cfg = CN()\n",
    "cfg.seed = 42\n",
    "cfg.batch_size = 32\n",
    "cfg.num_workers = 4\n",
    "cfg.lr = 1e-3\n",
    "cfg.epochs = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = '../datasets/sep28k/clips'\n",
    "label_path = '../datasets/sep28k/SEP-28k_labels_new.csv'\n",
    "trans  =  transforms.MelSpectrogram(win_length=400, hop_length=160, n_mels=40)    \n",
    "dataset = Sep28K(root = data_path, label_path = label_path, transforms=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.1, random_state=42)\n",
    "val_dataset, test_dataset = train_test_split(val_dataset, test_size=0.3, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train dataset: 19670\n",
      "Number of samples in validation dataset: 1530\n",
      "Number of samples in test dataset: 656\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples in train dataset:\", len(train_dataset))\n",
    "print(\"Number of samples in validation dataset:\", len(val_dataset))\n",
    "print(\"Number of samples in test dataset:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MTL Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_TYPE = 'mtl'\n",
    "\n",
    "model = LSTMModel(input_size=40, hidden_size=64, num_layers=1, output_size=6)\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "loss_t1 = nn.CrossEntropyLoss()\n",
    "loss_t2 = CCCLoss()\n",
    "t1_loss_train = AverageMeter(name='t1_loss_train', writer=_writer)\n",
    "t2_loss_train = AverageMeter(name='t2_loss_train', writer=_writer)\n",
    "t1_loss_val = AverageMeter(name='t1_loss_val', writer=_writer)\n",
    "t2_loss_val = AverageMeter(name='t2_loss_val', writer=_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, train_loader, val_loader, criterion, task_type, device, writer=None):\n",
    "    loss_t1, loss_t2 = criterion\n",
    "    t1_loss_train = AverageMeter(name='t1_loss_train', writer=writer)\n",
    "    t2_loss_train = AverageMeter(name='t2_loss_train', writer=writer)\n",
    "    t1_loss_val = AverageMeter(name='t1_loss_val', writer=writer)\n",
    "    t2_loss_val = AverageMeter(name='t2_loss_val', writer=writer)\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        t1_loss_train.reset()\n",
    "        t2_loss_train.reset()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            x, y_t1, y_t2, y = batch\n",
    "            x, y_t1, y_t2, y = x.to(device), y_t1.to(device), y_t2.to(device), y.to(device)\n",
    "            optimiser.zero_grad()\n",
    "            pred_t1, pred_t2 = model(x, task_type=task_type)\n",
    "            loss1, loss2 = 0, 0\n",
    "            if task_type == 'mtl':\n",
    "                loss1 = loss_t1(y_t1, pred_t1)\n",
    "                loss2 = loss_t2(y_t2, pred_t2)\n",
    "                loss = loss1 + loss2\n",
    "            elif task_type == 't1':\n",
    "                loss = loss_t1(y_t1, pred_t1)\n",
    "            else:\n",
    "                loss = loss_t2(y_t2, pred_t2)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            t1_loss_train.update(loss1.item())\n",
    "            t2_loss_train.update(loss2.item())\n",
    "\n",
    "        t1_loss_train.write(epoch)\n",
    "        t2_loss_train.write(epoch)\n",
    "\n",
    "        model.eval()\n",
    "        t1_loss_val.reset()\n",
    "        t2_loss_val.reset()\n",
    "\n",
    "        for i, (data, target) in enumerate(val_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            if task_type == 'mtl':\n",
    "                loss1 = loss_t1(output[0], target[:, 0])\n",
    "                loss2 = loss_t2(output[1], target[:, 1])\n",
    "            else:\n",
    "                loss = loss_t1(output, target)\n",
    "            t1_loss_val.update(loss1.item())\n",
    "            t2_loss_val.update(loss2.item())\n",
    "\n",
    "        t1_loss_val.write(epoch)\n",
    "        t2_loss_val.write(epoch)\n",
    "\n",
    "        print(f\"Epoch: {epoch}, T1 Loss: {t1_loss_train.avg}, T2 Loss: {t2_loss_train.avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Training MTL\n",
    "num_epochs = 100\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "patience = 10\n",
    "for epoch in range(num_epochs):\n",
    "    t1_loss_train.reset()\n",
    "    t2_loss_train.reset()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        X, y_t1, y_t2, y = batch\n",
    "        t1_pred, t2_pred = model(X.squeeze(1), task_type=TASK_TYPE)\n",
    "        loss_task_1 = loss_t1(t1_pred, y_t1)\n",
    "        loss_task_2 = loss_t2(t2_pred, y_t2)\n",
    "        t1_loss_train.update(loss_task_1.item(), X.size(0))\n",
    "        t2_loss_train.update(loss_task_2.item(), X.size(0))\n",
    "        loss = loss_task_1 + loss_task_2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    t1_loss_train.write(epoch)\n",
    "    t2_loss_train.write(epoch)\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t1_loss_val.reset()\n",
    "        t2_loss_val.reset()\n",
    "        for batch in test_loader:\n",
    "            X, y_t1, y_t2, y = batch\n",
    "            pred_t1, pred_t2 = model(X.squeeze(1), task_type=TASK_TYPE)\n",
    "            loss_task_1 = loss_t1(pred_t1, y_t1)\n",
    "            loss_task_2 = loss_t2(pred_t2, y_t2)\n",
    "            t1_loss_val.update(loss_task_1.item(), X.size(0))\n",
    "            t2_loss_val.update(loss_task_2.item(), X.size(0))\n",
    "        t1_loss_val.write(epoch)\n",
    "        t2_loss_val.write(epoch)\n",
    "    # setup early stopping\n",
    "    if t1_loss_val.avg + t2_loss_val.avg < best_loss:\n",
    "        best_loss = t1_loss_val.avg + t2_loss_val.avg\n",
    "        patience = 10\n",
    "    else:\n",
    "        patience -= 1\n",
    "\n",
    "    if patience == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "def test(model, test_loader, task_type='mtl'):\n",
    "    model.eval()\n",
    "    accuracy_t1 = AverageMeter()\n",
    "    accuracy_t2 = AverageMeter()\n",
    "    f1 = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            X, y_t1, y_t2, y = batch\n",
    "            pred_t1, pred_t2 = model(X.squeeze(1), task_type=task_type)\n",
    "            \n",
    "            if task_type == 'mtl' or task_type == 't1':\n",
    "                pred_t1 = torch.argmax(pred_t1, dim=1)\n",
    "                acc = (pred_t1 == y_t1).sum().item()\n",
    "                accuracy_t1.update(acc, X.size(0))\n",
    "\n",
    "            pred_t2 = torch.argmax(pred_t2, dim=1)\n",
    "            acc_fluency = (pred_t2 == y).sum().item()\n",
    "            accuracy_t2.update(acc_fluency, X.size(0))\n",
    "\n",
    "            f1.update(f1_score(y, pred_t2, average='weighted'), X.size(0))\n",
    "\n",
    "    return accuracy_t1.avg, accuracy_t2.avg, f1.avg\n",
    "\n",
    "print(test(model, test_loader, task_type=TASK_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_TYPE = 't2'\n",
    "\n",
    "model = LSTMModel(input_size=40, hidden_size=64, num_layers=1, output_size=6)\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "loss_t1 = nn.CrossEntropyLoss()\n",
    "loss_t2 = CCCLoss()\n",
    "t2_loss_train = AverageMeter(name='t2_loss_train', writer=_writer)\n",
    "t2_loss_val = AverageMeter(name='t2_loss_val', writer=_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Training t2\n",
    "num_epochs = 100\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "patience = 10\n",
    "for epoch in range(num_epochs):\n",
    "    t2_loss_train.reset()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        X, y_t1, y_t2, y = batch\n",
    "        t1_pred, t2_pred = model(X.squeeze(1), task_type=TASK_TYPE)\n",
    "        loss_task_2 = loss_t2(t2_pred, y_t2)\n",
    "        t2_loss_train.update(loss_task_2.item(), X.size(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    t2_loss_train.write(epoch)\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t1_loss_val.reset()\n",
    "        t2_loss_val.reset()\n",
    "        for batch in val_loader:\n",
    "            X, y_t1, y_t2, y = batch\n",
    "            pred_t1, pred_t2 = model(X.squeeze(1), task_type=TASK_TYPE)\n",
    "            loss_task_2 = loss_t2(pred_t2, y_t2)\n",
    "            t2_loss_val.update(loss_task_2.item(), X.size(0))\n",
    "        t2_loss_val.write(epoch)\n",
    "    # setup early stopping\n",
    "    if t2_loss_val.avg < best_loss:\n",
    "        best_loss = t2_loss_val.avg\n",
    "        patience = 10\n",
    "    else:\n",
    "        patience -= 1\n",
    "\n",
    "    if patience == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test(model, test_loader, task_type=TASK_TYPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ConvLSTM with MTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
