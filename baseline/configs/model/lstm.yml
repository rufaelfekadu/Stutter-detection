# model
model:
  name: 'lstm'
  hidden_size: 64
  num_layers: 2
  dropout: 0.3
  output_size: 6
  input_size: 43

solver:
  num_workers: 8
  batch_size: 32
  epochs: 300
  lr: 0.001
  es_patience: 200
  device: 'cuda'
  scheduler: 'none'
  factor: 0.5
  patience: 5
  min_lr: 0.000225
  losses: ['bce', 'bce']

# loss:
#   weights: [0.96, 0.98, 0.95, 0.94, 0.85, 0.65]

